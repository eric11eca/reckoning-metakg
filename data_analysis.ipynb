{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import random \n",
    "import copy\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from meta_kg.utils.py_io import *\n",
    "\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the|fail|or|naf)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "    \n",
    "    return white_space_fix(remove_articles(remove_punc(lower(text))))\n",
    "\n",
    "def compute_f1(prediction, truth):\n",
    "    pred_tokens = normalize_text(prediction).split()\n",
    "    truth_tokens = normalize_text(truth).split()\n",
    "\n",
    "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "        return int(pred_tokens == truth_tokens)\n",
    "\n",
    "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0\n",
    "\n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(truth_tokens)\n",
    "\n",
    "    return 2 * (prec * rec) / (prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out = read_json(\"./test_out.json\")\n",
    "answers = [data['answer'] for data in test_out]\n",
    "gen_outs = [data['gen_out'].split(\"?\")[1] for data in test_out]\n",
    "\n",
    "acc = 0\n",
    "acc_rel = 0\n",
    "acc_kg = 0\n",
    "f1_score = 0\n",
    "errors = []\n",
    "for pred, truth in zip(gen_outs, answers):\n",
    "    acc += int(normalize_text(pred) == normalize_text(truth))\n",
    "    f1_score += compute_f1(pred, truth)\n",
    "    if normalize_text(pred) != normalize_text(truth):\n",
    "        errors.append((pred, truth))\n",
    "    relation = truth.split(\"because\")[0]\n",
    "    facts = truth.split(\"because\")[1]\n",
    "    gen_rel = pred.split(\"because\")[0]\n",
    "    gen_facts = pred.split(\"because\")[1]\n",
    "    acc_rel += int(normalize_text(gen_rel) == normalize_text(relation))\n",
    "    acc_kg += int(normalize_text(gen_facts) == normalize_text(facts))\n",
    "\n",
    "print(\"Accuracy: \", acc/len(gen_outs))\n",
    "print(\"Accuracy (Relation): \", acc_rel/len(gen_outs))\n",
    "print(\"Accuracy (KG): \", acc_kg/len(gen_outs))\n",
    "print(\"F1 Score: \", f1_score/len(gen_outs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_exact_match(prediction, truth):\n",
    "    return int(normalize_text(truth) == normalize_text(prediction))\n",
    "\n",
    "\n",
    "targets = [data['answer'] for data in test_out]\n",
    "preds = [data['gen_out'].split(\"?\")[1] for data in test_out]\n",
    "\n",
    "if \"because\" in targets[0]:\n",
    "    labels = [t.split('because')[0].strip() for t in targets]\n",
    "    gen_labels = [p.split('because')[0].strip() for p in preds]\n",
    "    em_label = [compute_exact_match(\n",
    "        gen, label) for label, gen in zip(labels, gen_labels)]\n",
    "\n",
    "    facts = [t.split('because')[1].strip() for t in targets]\n",
    "    gen_kgs = [p.split('because')[1].strip() for p in preds]\n",
    "    em_kg = [compute_exact_match(\n",
    "        gen, label) for label, gen in zip(facts, gen_kgs)]\n",
    "    \n",
    "    print(\"Exact Match (Label): \", sum(em_label)/len(em_label))\n",
    "    print(\"Exact Match (KG): \", sum(em_kg)/len(em_kg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(errors[0][0], errors[0][1])\n",
    "compute_f1(errors[0][0], errors[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proof_3_hop= read_jsonl(\"./data/proof_3_hop/test.jsonl\")\n",
    "proof_3_hop[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folio_train = read_jsonl(\"./data/folio/train.jsonl\")\n",
    "\n",
    "folio_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(data['facts']) for data in folio_train]\n",
    "set(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folio_data = []\n",
    "for data in folio_train:\n",
    "    folio_data.append({\n",
    "        \"guid\": str(uuid.uuid4()),\n",
    "        \"question\": data['conclusion'],\n",
    "        \"answer\": data['label'].lower(),\n",
    "        \"facts\": data['premises'],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl(folio_data, \"./data/folio/dev.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "strategy = read_json(\"./data/strategyqa/strategyqa_train.json\")\n",
    "\n",
    "def parse_strategy(data):\n",
    "    question = data[\"question\"]\n",
    "    answer = \"yes\" if data[\"answer\"] else \"no\"\n",
    "    facts = [normalize_text(fact) for fact in data[\"facts\"]]\n",
    "    decomposition = data[\"decomposition\"]\n",
    "    example = {\n",
    "        \"guid\": str(uuid.uuid4()),\n",
    "        \"question\": question,\n",
    "        \"answer\": answer,\n",
    "        \"facts\": facts,\n",
    "        \"decomposition\": decomposition\n",
    "    }\n",
    "    return example\n",
    "\n",
    "strategy_data = [parse_strategy(data) for data in strategy]\n",
    "true_data = [data for data in strategy_data if data[\"answer\"] == \"yes\"]\n",
    "false_data = [data for data in strategy_data if data[\"answer\"] == \"no\"]\n",
    "\n",
    "train_true_data, dev_true_data = train_test_split(true_data, test_size=0.2, random_state=3042)\n",
    "train_false_data, dev_false_data = train_test_split(false_data, test_size=0.2, random_state=3042)\n",
    "\n",
    "train_data = train_true_data + train_false_data\n",
    "dev_data = dev_true_data + dev_false_data\n",
    "\n",
    "write_jsonl(train_data, \"./data/strategyqa/train.jsonl\")\n",
    "write_jsonl(dev_data, \"./data/strategyqa/dev.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy = read_jsonl(\"./data/taxonomy/hypernyms_training_mix_short_train.jsonl\")\n",
    "\n",
    "taxonomy_data = []\n",
    "for data in taxonomy:\n",
    "    data[\"guid\"] = data['id']\n",
    "    data[\"question\"] = normalize_text(data[\"phrase\"])\n",
    "    data[\"answer\"] = [\"no\", \"yes\"][data[\"answer\"]]\n",
    "    data[\"facts\"] = [normalize_text(fact) for fact in data[\"metadata\"][\"rules\"]]\n",
    "    example = {\n",
    "        \"guid\": data[\"guid\"],\n",
    "        \"question\": data[\"question\"],\n",
    "        \"answer\": data[\"answer\"],\n",
    "        \"facts\": data[\"facts\"],\n",
    "    }\n",
    "    taxonomy_data.append(example)\n",
    "taxonomy_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl(taxonomy_data, \"./data/taxonomy/train.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counting = read_jsonl(\"./data/counting/counting_training_mix_train.jsonl\")\n",
    "counting_data = []\n",
    "for data in counting:\n",
    "    data[\"guid\"] = data['id']\n",
    "    data[\"question\"] = data[\"phrase\"]\n",
    "    data[\"answer\"] = [\"no\", \"yes\"][data[\"answer\"]]\n",
    "    data[\"facts\"] = data[\"metadata\"][\"rules\"]\n",
    "    example = {\n",
    "        \"guid\": data[\"guid\"],\n",
    "        \"question\": data[\"question\"],\n",
    "        \"answer\": data[\"answer\"],\n",
    "        \"facts\": data[\"facts\"],\n",
    "    }\n",
    "    counting_data.append(example)\n",
    "counting_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl(counting_data, \"./data/counting/train.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clutrr2 = read_jsonl(\"./data/clutrr_2_hop/train.jsonl\")\n",
    "clutrr4 = read_jsonl(\"./data/clutrr_4_hop/train.jsonl\")\n",
    "clutrr6 = read_jsonl(\"./data/clutrr_6_hop/train.jsonl\")\n",
    "print(len(clutrr2))\n",
    "print(len(clutrr4))\n",
    "print(len(clutrr6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clutrr_all = random.sample(clutrr2, 50000) + random.sample(clutrr4, 50000) + random.sample(clutrr6, 50000)\n",
    "len(clutrr_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl(clutrr_all, \"./data/clutrr_mix/train.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "musique = read_jsonl(\"./data/musique/musique_full_v1.0_dev.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsat = read_json(\"./data/arlsat/train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "680"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_entailment_tree(instance, add_distractors=False):\n",
    "    hop = instance['depth_of_proof']\n",
    "    hypothesis = instance['hypothesis']\n",
    "    triples = instance[\"meta\"][\"triples\"]\n",
    "    distractor_ids = instance[\"meta\"][\"distractors\"]\n",
    "    fact_id = list(set(triples.keys()) - set(distractor_ids))\n",
    "    distractors = [triples[idx] for idx in distractor_ids]\n",
    "    facts = [triples[idx] for idx in fact_id]\n",
    "\n",
    "    num_distractors = len(facts) // 2\n",
    "    to_add = random.choices(distractors, k=num_distractors)\n",
    "    if add_distractors:\n",
    "        facts.extend(to_add)\n",
    "    random.shuffle(facts)\n",
    "\n",
    "    for i, fact in enumerate(facts):\n",
    "        if random.randint(0, 1):\n",
    "            facts[i] = random.choice(distractors)\n",
    "    \n",
    "    valid_example = {\n",
    "        \"guid\": str(uuid.uuid4()),\n",
    "        \"hypothesis\": hypothesis,\n",
    "        \"facts\": facts,\n",
    "        \"answer\": \"yes\",\n",
    "    }\n",
    "\n",
    "    invalid_example = {\n",
    "        \"guid\": str(uuid.uuid4()),\n",
    "        \"hypothesis\": hypothesis,\n",
    "        \"facts\": facts,\n",
    "        \"answer\": \"no\",\n",
    "    }\n",
    "    return valid_example, invalid_example\n",
    "\n",
    "entail_tree = read_jsonl(\"./data/entailment_tree/task_2/test.jsonl\")\n",
    "\n",
    "entail_data = []\n",
    "for instance in entail_tree:\n",
    "    valid, invalid = parse_entailment_tree(instance, add_distractors=False)\n",
    "    entail_data.append(valid)\n",
    "    entail_data.append(invalid)\n",
    "len(entail_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl(entail_data, \"./data/entailment_tree/test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entail_data = read_jsonl(\"./data/entailment_tree/train.jsonl\")\n",
    "depths = [len(instance['facts']) for instance in entail_data]\n",
    "max(depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.tagging\n",
    "\n",
    "predictor = Predictor.from_path(\n",
    "    \"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_proofwrite_cwa(instance):\n",
    "    triples = {}\n",
    "    for k,v in instance[\"triples\"].items():\n",
    "        triples[k] = v[\"text\"]\n",
    "    rules = {}\n",
    "    for k,v in instance[\"rules\"].items():\n",
    "        rules[k] = v[\"text\"]\n",
    "    questions = []\n",
    "    for q in instance['questions'].values():\n",
    "        question = q['question']\n",
    "        answer = q['answer']\n",
    "        proofs = q['proofs']\n",
    "        if '@' not in proofs:\n",
    "            proofs = set(normalize_text(proofs).split())\n",
    "        else:\n",
    "            proofs = proofs.split('=')[1]\n",
    "            proofs = set(normalize_text(proofs).split())\n",
    "        if len(proofs) > 1:\n",
    "            questions.append((question, str(answer).lower(), proofs))\n",
    "    return triples, rules, questions\n",
    "\n",
    "def _add_prefix(text):\n",
    "    pool = [\"It's wrong to say\", \"It's false to say\", \"It's incorrect to say\", \"It's not true that\", \"It's not correct that\", \"It's not the case that\"]\n",
    "    return random.choice(pool) + \" \" + text.lower()\n",
    "\n",
    "def _add_suffix(text):\n",
    "    pool = [\"is not true\", \"is not correct\", \"is not the case\", \"is wrong\", \"is false\", \"is incorrect\"]\n",
    "    return text + \" \" + random.choice(pool)\n",
    "\n",
    "def adversarial(text, label):\n",
    "    if label == \"true\":\n",
    "        try:\n",
    "            verb = predictor.predict(sentence=text)['verbs'][0]['verb']\n",
    "        except:\n",
    "            verb = \"12345\"\n",
    "        if verb == \"is\" or verb == \"are\":\n",
    "            convert = text.replace(verb, verb + \" not\")\n",
    "        else:\n",
    "            convert = text.replace(verb, \"does not \" + verb)\n",
    "        \n",
    "        if random.uniform(0, 1) > 0.5:\n",
    "            return _add_prefix(convert)\n",
    "        else:\n",
    "            return _add_suffix(convert)\n",
    "    else:\n",
    "        convert = text.replace(\"not \", \"\")\n",
    "        if random.uniform(0, 1) > 0.5:\n",
    "            return _add_prefix(convert)\n",
    "        else:\n",
    "            return _add_suffix(convert)\n",
    "\n",
    "def build_example(triples, rules, question):\n",
    "    example = {}\n",
    "    triples.update(rules)\n",
    "    example['guid'] = str(uuid.uuid4())\n",
    "    example['answer'] = question[1].lower()\n",
    "    # if random.uniform(0, 1) > 0.5:\n",
    "    #     example['question'] = adversarial(question[0], example['answer'])\n",
    "    # else:\n",
    "    example['question'] = question[0]\n",
    "    example['proofs'] = list(question[2])\n",
    "    example['facts'] = [triples[k] for k in question[2]]\n",
    "    example['facts'] = list(set(example['facts']))\n",
    "    #example['facts'] = [triples[k] for k in triples.keys()]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "146it [00:00, 6772.11it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/zemingchen/Desktop/meta-knowledge/data_analysis.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zemingchen/Desktop/meta-knowledge/data_analysis.ipynb#X40sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfor\u001b[39;00m example \u001b[39min\u001b[39;00m examples:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zemingchen/Desktop/meta-knowledge/data_analysis.ipynb#X40sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m# if len(example['facts']) < max_facts:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zemingchen/Desktop/meta-knowledge/data_analysis.ipynb#X40sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     pool \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(\u001b[39mlist\u001b[39m(triples\u001b[39m.\u001b[39mvalues()) \u001b[39m+\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zemingchen/Desktop/meta-knowledge/data_analysis.ipynb#X40sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m                 \u001b[39mlist\u001b[39m(rules\u001b[39m.\u001b[39mvalues())) \u001b[39m-\u001b[39m \u001b[39mset\u001b[39m(example[\u001b[39m'\u001b[39m\u001b[39mfacts\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zemingchen/Desktop/meta-knowledge/data_analysis.ipynb#X40sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     example[\u001b[39m'\u001b[39m\u001b[39mall_facts\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m example[\u001b[39m'\u001b[39m\u001b[39mfacts\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m (\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/zemingchen/Desktop/meta-knowledge/data_analysis.ipynb#X40sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         random\u001b[39m.\u001b[39;49mchoices(\u001b[39mlist\u001b[39;49m(pool), k\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zemingchen/Desktop/meta-knowledge/data_analysis.ipynb#X40sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m true_data \u001b[39m=\u001b[39m [e \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m examples \u001b[39mif\u001b[39;00m e[\u001b[39m'\u001b[39m\u001b[39manswer\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtrue\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zemingchen/Desktop/meta-knowledge/data_analysis.ipynb#X40sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m false_data \u001b[39m=\u001b[39m [e \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m examples \u001b[39mif\u001b[39;00m e[\u001b[39m'\u001b[39m\u001b[39manswer\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfalse\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal/lib/python3.9/random.py:486\u001b[0m, in \u001b[0;36mRandom.choices\u001b[0;34m(self, population, weights, cum_weights, k)\u001b[0m\n\u001b[1;32m    484\u001b[0m     floor \u001b[39m=\u001b[39m _floor\n\u001b[1;32m    485\u001b[0m     n \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m    \u001b[39m# convert to float for a small speed improvement\u001b[39;00m\n\u001b[0;32m--> 486\u001b[0m     \u001b[39mreturn\u001b[39;00m [population[floor(random() \u001b[39m*\u001b[39m n)] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m _repeat(\u001b[39mNone\u001b[39;00m, k)]\n\u001b[1;32m    487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     cum_weights \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(_accumulate(weights))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal/lib/python3.9/random.py:486\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    484\u001b[0m     floor \u001b[39m=\u001b[39m _floor\n\u001b[1;32m    485\u001b[0m     n \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m    \u001b[39m# convert to float for a small speed improvement\u001b[39;00m\n\u001b[0;32m--> 486\u001b[0m     \u001b[39mreturn\u001b[39;00m [population[floor(random() \u001b[39m*\u001b[39;49m n)] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m _repeat(\u001b[39mNone\u001b[39;00m, k)]\n\u001b[1;32m    487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     cum_weights \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(_accumulate(weights))\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "for hop in [2,3,5]:\n",
    "    for split in [\"train\", \"dev\", \"test\"]:\n",
    "        owa = read_jsonl(f\"./data/proofwriter/OWA/depth-{hop}/meta-{split}.jsonl\")\n",
    "        owa_2_hop = []\n",
    "        for i, data in tqdm(enumerate(owa)):\n",
    "            triples, rules, questions = parse_proofwrite_cwa(data)\n",
    "            examples = [build_example(triples, rules, q) for q in questions]\n",
    "            # all_facts = [fact for e in examples for fact in e['facts']]\n",
    "            # all_facts = list(set(all_facts))\n",
    "            # for example in examples:\n",
    "            #     example[\"all_facts\"] = all_facts\n",
    "            # num_facts = [len(example['facts']) for example in examples] \n",
    "            # max_facts = max(num_facts)\n",
    "            for example in examples:\n",
    "                # if len(example['facts']) < max_facts:\n",
    "                pool = set(list(triples.values()) +\n",
    "                            list(rules.values())) - set(example['facts'])\n",
    "                example['all_facts'] = example['facts'] + (\n",
    "                    random.choices(list(pool), k=1))\n",
    "            true_data = [e for e in examples if e['answer'] == \"true\"]\n",
    "            false_data = [e for e in examples if e['answer'] == \"false\"]\n",
    "            unknown_data = [e for e in examples if e['answer'] == \"unknown\"]\n",
    "            owa_2_hop.extend(random.choices(true_data, k=len(unknown_data)))\n",
    "            owa_2_hop.extend(random.choices(false_data, k=len(unknown_data)))\n",
    "            owa_2_hop.extend(unknown_data)\n",
    "        \n",
    "        print(len(owa_2_hop))\n",
    "        os.makedirs(f\"./data/owa_proof_{hop}_hop_d1\", exist_ok=True)\n",
    "        write_jsonl(owa_2_hop, f\"./data/owa_proof_{hop}_hop_d1/{split}.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "owa = read_jsonl(\"./data/proofwriter/OWA/NatLang/test.jsonl\")\n",
    "owa_add = read_jsonl(\"./data/proofwriter/OWA/birds-electricity/birds-electricity.jsonl\")\n",
    "owa_test = owa + owa_add\n",
    "\n",
    "answer2label = {\n",
    "    \"true\": \"entailment\",\n",
    "    \"false\": \"contradiction\",\n",
    "    \"unknown\": \"neutral\"\n",
    "}\n",
    "\n",
    "proofwriter_nli = []\n",
    "for data in owa_test:\n",
    "    triples, rules, questions = parse_proofwrite_cwa(data)\n",
    "    premise = list(triples.values()) + list(rules.values())\n",
    "    premise = \" \".join(premise)\n",
    "    for q in questions:\n",
    "        hypothesis = q[0]\n",
    "        label = q[1]\n",
    "        proofwriter_nli.append({\n",
    "            \"guid\": str(uuid.uuid4()),\n",
    "            \"premise\": premise,\n",
    "            \"hypothesis\": hypothesis,\n",
    "            \"label\": answer2label[label]\n",
    "        })\n",
    "\n",
    "proofwriter_nli[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl(proofwriter_nli, \"./data/proofwriter_nli/test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hop = 10\n",
    "\n",
    "pth = f\"./data/clutrr-system/forward/test/{hop}/long_proof_1.{hop}_test_facts_ANON.txt\"\n",
    "\n",
    "def parse_clutrr_line(line):\n",
    "    data = line.replace('<STORY>', \"\")\n",
    "    data = data.replace('<QUERY>', \"<>\")\n",
    "    data = data.replace('<ANSWER>', \"<>\")\n",
    "    data = data.replace('<PROOF>', \"<>\")\n",
    "    data = data.replace('ent_', \"person \")\n",
    "    data = data.split(\"<>\")\n",
    "    data = [d.strip() for d in data]\n",
    "    facts = data[0]\n",
    "    question = data[1]\n",
    "    answer = data[-1]\n",
    "    return {\n",
    "        \"guid\": str(uuid.uuid4()),\n",
    "        \"question\": question,\n",
    "        \"facts\": facts,\n",
    "        \"answer\": answer,\n",
    "    }\n",
    "\n",
    "with open(pth, \"r\") as reader:\n",
    "    lines = reader.readlines()\n",
    "    clutrr = [parse_clutrr_line(line) for line in lines]\n",
    "write_jsonl(clutrr, f\"./data/clutrr-system/test_{hop}_hop.jsonl\")\n",
    "clutrr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clutrr = read_jsonl(\"data/clutrr/dev.jsonl\")\n",
    "\n",
    "clutrr_4 = [x for x in clutrr if len(x[\"facts\"]) == 4]\n",
    "clutrr_6 = [x for x in clutrr if len(x[\"facts\"]) == 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rels = [\n",
    "    \"son\", \"daughter\",\n",
    "    \"brother\", \"sister\",\n",
    "    \"father\", \"mother\",\n",
    "    \"husband\", \"wife\",\n",
    "    \"grandfather\", \"grandmother\",\n",
    "    \"grandson\", \"granddaughter\",\n",
    "    \"uncle\", \"aunt\",\n",
    "    \"son-in-law\", \"daughter-in-law\",\n",
    "    \"father-in-law\", \"mother-in-law\",\n",
    "    \"brother-in-law\", \"sister-in-law\",\n",
    "    \"nephew\", \"niece\"\n",
    "]\n",
    "\n",
    "persons = [\n",
    "    'A', 'B', 'C', 'D', \n",
    "    'H', 'J', 'K', 'L', \n",
    "    'M', 'N', 'O', 'P', \n",
    "    'Q', 'R', 'S', 'T',\n",
    "    'V', 'X', 'Y', 'Z',]\n",
    "\n",
    "entity_map = {}\n",
    "for i, p in enumerate(persons):\n",
    "    entity_map[p] = str(i+1)\n",
    "\n",
    "def get_knowledge(tokens):\n",
    "    entity = []\n",
    "    relation = None\n",
    "    for tok in tokens:\n",
    "        if tok.isdigit():\n",
    "            entity.append(persons[int(tok)-1])\n",
    "        if tok in rels:\n",
    "            relation = tok\n",
    "    assert len(entity) == 2\n",
    "    if relation is None:\n",
    "        print(tokens)\n",
    "    return entity, relation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify(dataset):\n",
    "    simple_dataset = copy.deepcopy(dataset)\n",
    "    for data in simple_dataset:\n",
    "        facts = []\n",
    "        facts_raw = data['facts'].split(\". \")\n",
    "        for fact in facts_raw:\n",
    "            tokens = fact.split()\n",
    "            entity, relation = get_knowledge(tokens)\n",
    "            facts.append([' '.join(entity), relation])\n",
    "        data['facts'] = facts\n",
    "        question = data['question']\n",
    "        answer = data['answer']\n",
    "        tokens = answer.split()\n",
    "        entity, relation = get_knowledge(tokens)\n",
    "        qa_pair = []\n",
    "        \n",
    "        qa_pair.append(question)\n",
    "        # qa_pair[0] = qa_pair[0].replace(entity_map[entity[0]], entity[0])\n",
    "        # qa_pair[0] = qa_pair[0].replace(entity_map[entity[1]], entity[1])\n",
    "        # qa_pair[0] = qa_pair[0].replace(\"person \", \"\")\n",
    "        qa_pair[0] = f\"How are {entity[0]} and {entity[1]} related to each other ?\"\n",
    "        qa_pair.append(' '.join(entity))\n",
    "        qa_pair.append(relation)\n",
    "        data['questions'] = [qa_pair]\n",
    "    return simple_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "hop = 10\n",
    "clutrr = read_jsonl(f\"data/clutrr-system/test_{hop}_hop.jsonl\")\n",
    "simple_clutrr =  simplify(clutrr)\n",
    "\n",
    "os.makedirs(f\"data/clutrr_{hop}_hop\", exist_ok=True)\n",
    "write_jsonl(simple_clutrr, f\"data/clutrr_{hop}_hop/test.jsonl\")\n",
    "\n",
    "simple_clutrr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_clutrr_4 = simplify(clutrr_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl(simple_clutrr_4, \"data/clutrr_4_hop/dev.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_clutrr_6 = simplify(clutrr_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl(simple_clutrr_6, \"data/clutrr_6_hop/dev.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_out_4_hop = read_json(\"./output/20221212-033351/dev_out-epoch=0_step=5061.json\")\n",
    "eval_out_4_hop[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0 \n",
    "for data in eval_out_4_hop:\n",
    "    gen_out= data['gen_out'].split(\"?\")\n",
    "    gen_answer = gen_out[1].strip()\n",
    "    if gen_answer == data['answer']:\n",
    "        acc += 1\n",
    "print(acc/len(eval_out_4_hop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proof_5_hop = read_jsonl(\"./data/proof_5_hop_hard/train.jsonl\")\n",
    "\n",
    "sort_by_proof = {}\n",
    "for data in proof_5_hop:\n",
    "    key = \",\".join(data['facts'])\n",
    "    if key not in sort_by_proof:\n",
    "        sort_by_proof[key] = [data]\n",
    "    else:\n",
    "        sort_by_proof[key].append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_k = [len(data['facts']) for data in proof_5_hop]\n",
    "max(num_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sort_by_proof), len(proof_5_hop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_question = list(sort_by_proof.items())\n",
    "multi_question[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "meta_2_hop = [0.988, 0.5113, 0.414, 0.3526, 0.316]\n",
    "meta_4_hop = [0.99, 0.9631, 0.819, 0.6452, 0.4608]\n",
    "meta_6_hop = [0.9994, 0.9592, 0.9731, 0.9208, 0.799]\n",
    "meta_clutrr = [meta_2_hop, meta_4_hop, meta_6_hop]\n",
    "\n",
    "cmap = sns.cm.rocket_r\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    meta_clutrr, \n",
    "    annot=True, \n",
    "    square=True, \n",
    "    linewidth=3.0, \n",
    "    xticklabels=[2, 4, 6, 8, 10],\n",
    "    yticklabels=[2, 4, 6],\n",
    "    cbar=False,\n",
    "    cmap=cmap)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_2_hop = [0.981, 0.4432, 0.3717, 0.3258, 0.217]\n",
    "baseline_4_hop = [0.9117, 0.8924, 0.8044, 0.7734, 0.6063]\n",
    "baseline_6_hop = [1.0, 0.9706, 0.9546, 0.9054, 0.7622]\n",
    "baseline_clutrr = [baseline_2_hop, baseline_4_hop, baseline_6_hop]\n",
    "\n",
    "cmap = sns.cm.rocket_r\n",
    "ax = sns.heatmap(\n",
    "    baseline_clutrr, \n",
    "    annot=True, \n",
    "    square=True, \n",
    "    linewidth=3.0, \n",
    "    xticklabels=[2, 4, 6, 8, 10],\n",
    "    yticklabels=[2, 4, 6], \n",
    "    cbar=False,\n",
    "    cmap=cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "proof_2_hop = [0.998, 0.961, 0.863]\n",
    "proof_3_hop = [0, 0.956, 0.866]\n",
    "proof_5_hop = [0, 0 , 0.977]\n",
    "\n",
    "proof = [proof_2_hop, proof_3_hop, proof_5_hop]\n",
    "\n",
    "mask = 1 - np.triu(np.ones_like(proof, dtype=np.bool))\n",
    "mask = [[0,0,0],\n",
    "        [1,0,0],\n",
    "        [1,1,0]]\n",
    "mask = np.array(mask)\n",
    "heatmap = sns.heatmap(proof, mask=mask, xticklabels=[2,3,5], yticklabels=[2,3,5], vmin=0, vmax=1, annot=True, cmap='Blues', cbar=False, annot_kws={\"fontsize\":18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "\n",
    "plt.style.use([\"nature\", \"grid\", \"ieee\"])\n",
    "\n",
    "# sns.set(font_scale=1.5)\n",
    "\n",
    "x = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "plt.figure(figsize=(5, 4))\n",
    "meta_6_hop = [100,95.5,96,94.65,94.85,95.7,90,84.5,80]\n",
    "baseline_6_hop = [100,95.4,90,89.1,90.34,87.6,81.6,75,67.9]\n",
    "\n",
    "plt.plot(\n",
    "    x, meta_6_hop, \n",
    "    'o-', color='#fdb462', \n",
    "    alpha=1.0, label='Meta-kg-6', \n",
    "    linewidth='2', ms=5)\n",
    "plt.plot(\n",
    "    x, baseline_6_hop, \n",
    "    's-', color='#7fb1d3', \n",
    "    alpha=1.0, label='Baseline-6', \n",
    "    linewidth='2', ms=5)\n",
    "\n",
    "plt.ylim(20, 100)\n",
    "\n",
    "#plt.grid(axis='x', color='0.95')\n",
    "plt.legend()\n",
    "plt.title('6-hop Clutrr Generalization')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [2, 4, 6, 8, 10]\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.plot(x, meta_4_hop, 'o-', color='orange', alpha=0.9, label='Meta-kg')\n",
    "plt.plot(x, baseline_4_hop, 's-', color='blue', alpha=0.9, label='Baseline')\n",
    "plt.ylim(0, 1.1)\n",
    "\n",
    "plt.grid(axis='x', color='0.95')\n",
    "plt.legend()\n",
    "plt.title('4-hop Clutrr Generalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_2_hop = [0.988, 0.5113, 0.414, 0.3526, 0.316]\n",
    "baseline_2_hop = [0.981, 0.4432, 0.3717, 0.3258, 0.217]\n",
    "x = [2, 4, 6, 8, 10]\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.plot(x, meta_2_hop, 'o-', color='orange', alpha=0.9, label='Meta-kg')\n",
    "plt.plot(x, baseline_2_hop, 's-', color='blue', alpha=0.9, label='Baseline')\n",
    "plt.ylim(0, 1.1)\n",
    "\n",
    "plt.grid(axis='x', color='0.95')\n",
    "plt.legend()\n",
    "plt.title('2-hop Clutrr Generalization')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "470f44e489c3417f40e6fbafbb8f6893ee0c258fcccc4737e0ea9152abfd2d49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
