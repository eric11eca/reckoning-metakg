{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import random \n",
    "import copy\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from meta_kg.utils.py_io import *\n",
    "\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the|fail|or|naf)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "    \n",
    "    return white_space_fix(remove_articles(remove_punc(lower(text))))\n",
    "\n",
    "def compute_f1(prediction, truth):\n",
    "    pred_tokens = normalize_text(prediction).split()\n",
    "    truth_tokens = normalize_text(truth).split()\n",
    "\n",
    "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "        return int(pred_tokens == truth_tokens)\n",
    "\n",
    "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0\n",
    "\n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(truth_tokens)\n",
    "\n",
    "    return 2 * (prec * rec) / (prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9641782882143833\n",
      "Accuracy (Relation):  0.9657278279099444\n",
      "Accuracy (KG):  0.983501959711968\n",
      "F1 Score:  0.8912978796490217\n"
     ]
    }
   ],
   "source": [
    "test_out = read_json(\"./output/test_out.json\")\n",
    "answers = [data['answer'] for data in test_out]\n",
    "gen_outs = [data['gen_out'].split(\"?\")[1] for data in test_out]\n",
    "\n",
    "acc = 0\n",
    "acc_rel = 0\n",
    "acc_kg = 0\n",
    "f1_score = 0\n",
    "errors = []\n",
    "for pred, truth in zip(gen_outs, answers):\n",
    "    acc += int(normalize_text(pred) == normalize_text(truth))\n",
    "    f1_score += compute_f1(pred, truth)\n",
    "    if normalize_text(pred) != normalize_text(truth):\n",
    "        errors.append((pred, truth))\n",
    "    relation = truth.split(\"because\")[0]\n",
    "    facts = truth.split(\"because\")[1]\n",
    "    gen_rel = pred.split(\"because\")[0]\n",
    "    gen_facts = pred.split(\"because\")[1]\n",
    "    acc_rel += int(normalize_text(gen_rel) == normalize_text(relation))\n",
    "    acc_kg += int(normalize_text(gen_facts) == normalize_text(facts))\n",
    "\n",
    "print(\"Accuracy: \", acc/len(gen_outs))\n",
    "print(\"Accuracy (Relation): \", acc_rel/len(gen_outs))\n",
    "print(\"Accuracy (KG): \", acc_kg/len(gen_outs))\n",
    "print(\"F1 Score: \", f1_score/len(gen_outs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match (Label):  0.9657278279099444\n",
      "Exact Match (KG):  0.983501959711968\n"
     ]
    }
   ],
   "source": [
    "def compute_exact_match(prediction, truth):\n",
    "    return int(normalize_text(truth) == normalize_text(prediction))\n",
    "\n",
    "\n",
    "targets = [data['answer'] for data in test_out]\n",
    "preds = [data['gen_out'].split(\"?\")[1] for data in test_out]\n",
    "\n",
    "if \"because\" in targets[0]:\n",
    "    labels = [t.split('because')[0].strip() for t in targets]\n",
    "    gen_labels = [p.split('because')[0].strip() for p in preds]\n",
    "    em_label = [compute_exact_match(\n",
    "        gen, label) for label, gen in zip(labels, gen_labels)]\n",
    "\n",
    "    facts = [t.split('because')[1].strip() for t in targets]\n",
    "    gen_kgs = [p.split('because')[1].strip() for p in preds]\n",
    "    em_kg = [compute_exact_match(\n",
    "        gen, label) for label, gen in zip(facts, gen_kgs)]\n",
    "    \n",
    "    print(\"Exact Match (Label): \", sum(em_label)/len(em_label))\n",
    "    print(\"Exact Match (KG): \", sum(em_kg)/len(em_kg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "father because T X husband,B T father father-in-law because T X husband,B T father\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(errors[0][0], errors[0][1])\n",
    "compute_f1(errors[0][0], errors[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "strategy = read_json(\"./data/strategyqa/strategyqa_train.json\")\n",
    "\n",
    "def parse_strategy(data):\n",
    "    question = data[\"question\"]\n",
    "    answer = \"yes\" if data[\"answer\"] else \"no\"\n",
    "    facts = [normalize_text(fact) for fact in data[\"facts\"]]\n",
    "    decomposition = data[\"decomposition\"]\n",
    "    example = {\n",
    "        \"guid\": str(uuid.uuid4()),\n",
    "        \"question\": question,\n",
    "        \"answer\": answer,\n",
    "        \"facts\": facts,\n",
    "        \"decomposition\": decomposition\n",
    "    }\n",
    "    return example\n",
    "\n",
    "strategy_data = [parse_strategy(data) for data in strategy]\n",
    "true_data = [data for data in strategy_data if data[\"answer\"] == \"yes\"]\n",
    "false_data = [data for data in strategy_data if data[\"answer\"] == \"no\"]\n",
    "\n",
    "train_true_data, dev_true_data = train_test_split(true_data, test_size=0.2, random_state=3042)\n",
    "train_false_data, dev_false_data = train_test_split(false_data, test_size=0.2, random_state=3042)\n",
    "\n",
    "train_data = train_true_data + train_false_data\n",
    "dev_data = dev_true_data + dev_false_data\n",
    "\n",
    "write_jsonl(train_data, \"./data/strategyqa/train.jsonl\")\n",
    "write_jsonl(dev_data, \"./data/strategyqa/dev.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guid': 'afdf807efc8b55e8b1c9349c0ac554ca',\n",
       " 'question': 'reggae is capable of express feelings',\n",
       " 'answer': 'yes',\n",
       " 'facts': ['music is capable of express feelings',\n",
       "  'reggae is music',\n",
       "  'holly is capable of branch out',\n",
       "  'plant is not capable of express feelings',\n",
       "  'tulip is plant',\n",
       "  'reggae is auditory communication',\n",
       "  'mustard is not capable of shade from sun',\n",
       "  'reggae is not vertebrate']}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxonomy = read_jsonl(\"./data/taxonomy/hypernyms_training_mix_short_dev.jsonl\")\n",
    "\n",
    "taxonomy_data = []\n",
    "for data in taxonomy:\n",
    "    data[\"guid\"] = data['id']\n",
    "    data[\"question\"] = normalize_text(data[\"phrase\"])\n",
    "    data[\"answer\"] = [\"np\", \"yes\"][data[\"answer\"]]\n",
    "    data[\"facts\"] = [normalize_text(fact) for fact in data[\"metadata\"][\"rules\"]]\n",
    "    example = {\n",
    "        \"guid\": data[\"guid\"],\n",
    "        \"question\": data[\"question\"],\n",
    "        \"answer\": data[\"answer\"],\n",
    "        \"facts\": data[\"facts\"],\n",
    "    }\n",
    "    taxonomy_data.append(example)\n",
    "taxonomy_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl(taxonomy_data, \"./data/taxonomy/dev.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guid': '8f836112dccfa8f61fc934f114145a2c',\n",
       " 'question': 'James H. Roberts is the CEO of ADT.',\n",
       " 'answer': 'np',\n",
       " 'facts': ['Timothy J. Whall is the CEO of ADT.', 'ADT has one CEO.']}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counting = read_jsonl(\"./data/counting/counting_training_mix_dev.jsonl\")\n",
    "counting_data = []\n",
    "for data in counting:\n",
    "    data[\"guid\"] = data['id']\n",
    "    data[\"question\"] = data[\"phrase\"]\n",
    "    data[\"answer\"] = [\"np\", \"yes\"][data[\"answer\"]]\n",
    "    data[\"facts\"] = data[\"metadata\"][\"rules\"]\n",
    "    example = {\n",
    "        \"guid\": data[\"guid\"],\n",
    "        \"question\": data[\"question\"],\n",
    "        \"answer\": data[\"answer\"],\n",
    "        \"facts\": data[\"facts\"],\n",
    "    }\n",
    "    counting_data.append(example)\n",
    "counting_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl(counting_data, \"./data/counting/dev.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96011\n",
      "89971\n",
      "90922\n"
     ]
    }
   ],
   "source": [
    "clutrr2 = read_jsonl(\"./data/clutrr_2_hop/train.jsonl\")\n",
    "clutrr4 = read_jsonl(\"./data/clutrr_4_hop/train.jsonl\")\n",
    "clutrr6 = read_jsonl(\"./data/clutrr_6_hop/train.jsonl\")\n",
    "print(len(clutrr2))\n",
    "print(len(clutrr4))\n",
    "print(len(clutrr6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clutrr_all = random.sample(clutrr2, 50000) + random.sample(clutrr4, 50000) + random.sample(clutrr6, 50000)\n",
    "len(clutrr_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl(clutrr_all, \"./data/clutrr_mix/train.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "musique = read_jsonl(\"./data/musique/musique_full_v1.0_dev.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsat = read_json(\"./data/arlsat/train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "680"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_entailment_tree(instance, add_distractors=False):\n",
    "    hop = instance['depth_of_proof']\n",
    "    hypothesis = instance['hypothesis']\n",
    "    triples = instance[\"meta\"][\"triples\"]\n",
    "    distractor_ids = instance[\"meta\"][\"distractors\"]\n",
    "    fact_id = list(set(triples.keys()) - set(distractor_ids))\n",
    "    distractors = [triples[idx] for idx in distractor_ids]\n",
    "    facts = [triples[idx] for idx in fact_id]\n",
    "\n",
    "    num_distractors = len(facts) // 2\n",
    "    to_add = random.choices(distractors, k=num_distractors)\n",
    "    if add_distractors:\n",
    "        facts.extend(to_add)\n",
    "    random.shuffle(facts)\n",
    "\n",
    "    for i, fact in enumerate(facts):\n",
    "        if random.randint(0, 1):\n",
    "            facts[i] = random.choice(distractors)\n",
    "    \n",
    "    valid_example = {\n",
    "        \"guid\": str(uuid.uuid4()),\n",
    "        \"hypothesis\": hypothesis,\n",
    "        \"facts\": facts,\n",
    "        \"answer\": \"yes\",\n",
    "    }\n",
    "\n",
    "    invalid_example = {\n",
    "        \"guid\": str(uuid.uuid4()),\n",
    "        \"hypothesis\": hypothesis,\n",
    "        \"facts\": facts,\n",
    "        \"answer\": \"no\",\n",
    "    }\n",
    "    return valid_example, invalid_example\n",
    "\n",
    "entail_tree = read_jsonl(\"./data/entailment_tree/task_2/test.jsonl\")\n",
    "\n",
    "entail_data = []\n",
    "for instance in entail_tree:\n",
    "    valid, invalid = parse_entailment_tree(instance, add_distractors=False)\n",
    "    entail_data.append(valid)\n",
    "    entail_data.append(invalid)\n",
    "len(entail_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl(entail_data, \"./data/entailment_tree/test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entail_data = read_jsonl(\"./data/entailment_tree/train.jsonl\")\n",
    "depths = [len(instance['facts']) for instance in entail_data]\n",
    "max(depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_proofwrite_cwa(instance):\n",
    "    triples = {}\n",
    "    for k,v in instance[\"triples\"].items():\n",
    "        triples[k] = v[\"text\"]\n",
    "    rules = {}\n",
    "    for k,v in instance[\"rules\"].items():\n",
    "        rules[k] = v[\"text\"]\n",
    "    questions = []\n",
    "    for q in instance['questions'].values():\n",
    "        question = q['question']\n",
    "        answer = q['answer']\n",
    "        proofs = q['proofs']\n",
    "        if '@' not in proofs:\n",
    "            proofs = set(normalize_text(proofs).split())\n",
    "        else:\n",
    "            proofs = proofs.split('=')[1]\n",
    "            proofs = set(normalize_text(proofs).split())\n",
    "        if len(proofs) > 1:\n",
    "            questions.append((question, str(answer).lower(), proofs))\n",
    "    return triples, rules, questions\n",
    "\n",
    "def build_example(triples, rules, question):\n",
    "    example = {}\n",
    "    triples.update(rules)\n",
    "    example['guid'] = str(uuid.uuid4())\n",
    "    example['question'] = question[0]\n",
    "    example['answer'] = question[1]\n",
    "    example['proofs'] = list(question[2])\n",
    "    example['knowledge'] = [triples[k] for k in question[2]]\n",
    "    example['knowledge'] = list(set(example['knowledge']))\n",
    "    example['facts'] = [triples[k] for k in triples.keys()]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29457\n",
      "4265\n",
      "8340\n",
      "34516\n",
      "5170\n",
      "10113\n",
      "42754\n",
      "6091\n",
      "12078\n"
     ]
    }
   ],
   "source": [
    "for hop in [2,3,5]:\n",
    "    for split in [\"train\", \"dev\", \"test\"]:\n",
    "        owa = read_jsonl(f\"./data/proofwriter/CWA/depth-{hop}/meta-{split}.jsonl\")\n",
    "        owa_2_hop = []\n",
    "        for i, data in enumerate(owa):\n",
    "            triples, rules, questions = parse_proofwrite_cwa(data)\n",
    "            examples = [build_example(triples, rules, q) for q in questions]\n",
    "            owa_2_hop.extend(examples)\n",
    "        \n",
    "        print(len(owa_2_hop))\n",
    "        write_jsonl(owa_2_hop, f\"./data/proof_{hop}_hop_hard/{split}.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clutrr = read_jsonl(\"data/clutrr/dev.jsonl\")\n",
    "\n",
    "clutrr_4 = [x for x in clutrr if len(x[\"facts\"]) == 4]\n",
    "clutrr_6 = [x for x in clutrr if len(x[\"facts\"]) == 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rels = [\n",
    "    \"son\", \"daughter\",\n",
    "    \"brother\", \"sister\",\n",
    "    \"father\", \"mother\",\n",
    "    \"husband\", \"wife\",\n",
    "    \"grandfather\", \"grandmother\",\n",
    "    \"grandson\", \"granddaughter\",\n",
    "    \"uncle\", \"aunt\",\n",
    "    \"son-in-law\", \"daughter-in-law\",\n",
    "    \"father-in-law\", \"mother-in-law\",\n",
    "    \"brother-in-law\", \"sister-in-law\",\n",
    "    \"nephew\", \"niece\"\n",
    "]\n",
    "\n",
    "persons = [\n",
    "    'A', 'B', 'C', 'D', \n",
    "    'H', 'J', 'K', 'L', \n",
    "    'M', 'N', 'O', 'P', \n",
    "    'Q', 'R', 'S', 'T',\n",
    "    'V', 'X', 'Y', 'Z',]\n",
    "\n",
    "def get_knowledge(tokens):\n",
    "    entitiy = []\n",
    "    relation = None\n",
    "    for tok in tokens:\n",
    "        if tok.isdigit():\n",
    "            entitiy.append(persons[int(tok)-1])\n",
    "        if tok in rels:\n",
    "            relation = tok\n",
    "    assert len(entitiy) == 2\n",
    "    if relation is None:\n",
    "        print(tokens)\n",
    "    return ' '.join(entitiy), relation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify(dataset):\n",
    "    simple_dataset = copy.deepcopy(dataset)\n",
    "    for data in simple_dataset:\n",
    "        facts = []\n",
    "        for fact in data['facts']:\n",
    "            tokens = fact.split()\n",
    "            entity, relation = get_knowledge(tokens)\n",
    "            facts.append((entity, relation))\n",
    "        data['facts'] = facts\n",
    "        for question in data['questions']:\n",
    "            answer = question[1]\n",
    "            tokens = answer.split()\n",
    "            entity, relation = get_knowledge(tokens)\n",
    "            question[0] = f\"How are {entity[0]} and {entity[-1]} related to each other ?\"\n",
    "            question[1] = entity\n",
    "            assert len(question[0].split()) == 10\n",
    "            question.append(relation)\n",
    "    return simple_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_clutrr_4 = simplify(clutrr_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl(simple_clutrr_4, \"data/clutrr_4_hop/dev.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_clutrr_6 = simplify(clutrr_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl(simple_clutrr_6, \"data/clutrr_6_hop/dev.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guid': 'e6e0679a-2081-4863-bbb2-13b08fe283e9',\n",
       " 'prefix': 'clutrr_4_hop',\n",
       " 'question': '<|endoftext|>C B aunt\\nH J sister\\nB J daughter\\nZ H daughter\\nBased on fact_0 fact_1 fact_2 fact_3, How are C and Z related to each other ?',\n",
       " 'gen_out': 'C B aunt\\nH J sister\\nB J daughter\\nZ H daughter\\nBased on fact_0 fact_1 fact_2 fact_3, How are C and Z related to each other?daughter',\n",
       " 'answer': 'daughter'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_out_4_hop = read_json(\"./output/20221212-033351/dev_out-epoch=0_step=5061.json\")\n",
    "eval_out_4_hop[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89\n"
     ]
    }
   ],
   "source": [
    "acc = 0 \n",
    "for data in eval_out_4_hop:\n",
    "    gen_out= data['gen_out'].split(\"?\")\n",
    "    gen_answer = gen_out[1].strip()\n",
    "    if gen_answer == data['answer']:\n",
    "        acc += 1\n",
    "print(acc/len(eval_out_4_hop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "proof_5_hop = read_jsonl(\"./data/proof_5_hop_hard/train.jsonl\")\n",
    "\n",
    "sort_by_proof = {}\n",
    "for data in proof_5_hop:\n",
    "    key = \",\".join(data['facts'])\n",
    "    if key not in sort_by_proof:\n",
    "        sort_by_proof[key] = [data]\n",
    "    else:\n",
    "        sort_by_proof[key].append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_k = [len(data['facts']) for data in proof_5_hop]\n",
    "max(num_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(501, 6091)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sort_by_proof), len(proof_5_hop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('White things are red.,Erin is white.,Erin is furry.,If something is nice and white then it is smart.,All furry, red things are nice.',\n",
       " [{'guid': '7b9c8377-e480-4d7d-aeae-c835af0a4f16',\n",
       "   'question': 'Erin is smart.',\n",
       "   'answer': 'true',\n",
       "   'proofs': ['rule3', 'triple4', 'rule8', 'triple3', 'rule4'],\n",
       "   'facts': ['White things are red.',\n",
       "    'Erin is white.',\n",
       "    'Erin is furry.',\n",
       "    'If something is nice and white then it is smart.',\n",
       "    'All furry, red things are nice.']},\n",
       "  {'guid': '54708a90-6298-49c8-bc66-63453a3cdf31',\n",
       "   'question': 'Erin is not smart.',\n",
       "   'answer': 'false',\n",
       "   'proofs': ['rule3', 'triple4', 'rule8', 'triple3', 'rule4'],\n",
       "   'facts': ['White things are red.',\n",
       "    'Erin is white.',\n",
       "    'Erin is furry.',\n",
       "    'If something is nice and white then it is smart.',\n",
       "    'All furry, red things are nice.']}])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_question = list(sort_by_proof.items())\n",
    "multi_question[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "470f44e489c3417f40e6fbafbb8f6893ee0c258fcccc4737e0ea9152abfd2d49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
