{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meta_kg.utils.py_io import *\n",
    "\n",
    "# dynamic = read_json(\"./output/20221124-010221/dev_out-epoch=0_step=11250.json\")\n",
    "# dynamic = read_json(\"./output/20221129-195134/dev_out-epoch=0_step=11250.json\")\n",
    "dynamic = read_json(\"./output/20221205-051520/dev_out-epoch=0_step=3600.json\")\n",
    "\n",
    "inner_loss_token_dynamic = []\n",
    "topk_tokens_dynamic = []\n",
    "inner_loss_dynamic = []\n",
    "for log in dynamic:\n",
    "    inner_loss = log[\"inner_loss\"]\n",
    "    topk_tokens = log[\"topk_tokens\"]\n",
    "    inner_loss_token = log[\"inner_loss_token\"]\n",
    "    inner_loss_dynamic.append(inner_loss)\n",
    "    topk_tokens_dynamic.append(topk_tokens)\n",
    "    inner_loss_token_dynamic.append(inner_loss_token)\n",
    "\n",
    "inner_loss_token_dynamic[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_outs = [' '.join(out['gen_out'].split()[1:4]) for out in dynamic]\n",
    "answers = [out['answer'] for out in dynamic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "for i in range(len(gen_outs)):\n",
    "    if gen_outs[i] == answers[i]:\n",
    "        acc += 1\n",
    "acc / len(gen_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = 0\n",
    "\n",
    "\n",
    "def plot_loss_token(inner_loss_token, index):\n",
    "    plasma = plt.get_cmap('tab20c')\n",
    "    def rescale(y): return (y - np.min(y)) / (np.max(y) - np.min(y))\n",
    "\n",
    "    for token_loss in inner_loss_token:\n",
    "        tokens = [tok for tok in list(token_loss.keys())]\n",
    "        tokens.reverse()\n",
    "        losses = [round(loss[0], 3) for loss in list(token_loss.values())]\n",
    "        losses.reverse()\n",
    "\n",
    "        plt.figure(figsize=(10, 2))\n",
    "        plt.barh(tokens, losses, color=plasma(rescale(losses)), height=0.5)\n",
    "        plt.xticks(rotation=0, fontsize=15)\n",
    "        plt.yticks(rotation=0, fontsize=15)\n",
    "        for i, v in enumerate(losses):\n",
    "            plt.text(v, i, \" \"+str(v), color='blue',\n",
    "                     va='center', fontweight='bold')\n",
    "\n",
    "        # plt.savefig(f'./output/token_loss_{index}.png', bbox_inches='tight', dpi=300)\n",
    "        index += 1\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "plot_loss_token(inner_loss_token_dynamic[0], index)\n",
    "plot_loss_token(inner_loss_token_dynamic[10], index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_topk_token(topk_tokens, index):\n",
    "    plasma = plt.get_cmap('tab20c')\n",
    "    def rescale(y): return (y - np.min(y)) / (np.max(y) - np.min(y))\n",
    "\n",
    "    for record in topk_tokens:\n",
    "        orig = record[0][0]\n",
    "        tokens = [tok[1] for tok in record[:5]]\n",
    "        probs = [tok[2] for tok in record[:5]]\n",
    "\n",
    "        assert(len(tokens) == len(probs))\n",
    "\n",
    "        tokens.reverse()\n",
    "        probs.reverse()\n",
    "        # print(tokens)\n",
    "        # print(probs)\n",
    "\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.barh(tokens, probs, color=plasma(rescale(probs)), height=0.5)\n",
    "        plt.xticks(rotation=0, fontsize=15)\n",
    "        plt.yticks(rotation=0, fontsize=15)\n",
    "        plt.title(f\"Original token: {orig}\", fontsize=15, fontweight='bold')\n",
    "        for i, v in enumerate(probs):\n",
    "            plt.text(v, i, \" \"+str(v), color='blue',\n",
    "                     va='center', fontweight='bold')\n",
    "        # plt.savefig(f'./output/token_loss_{index}.png', bbox_inches='tight', dpi=300)\n",
    "        index += 1\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "index = 0\n",
    "plot_topk_token(topk_tokens_dynamic[0][1], index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_loss = []\n",
    "for inner_loss_token in inner_loss_token_dynamic[:1000]:\n",
    "    for token_loss in inner_loss_token:\n",
    "        losses = [loss[0] for loss in list(token_loss.values())[1:]]\n",
    "        for loss in losses:\n",
    "            all_loss.append(loss)\n",
    "all_loss = np.array(all_loss)\n",
    "q25, q75 = np.percentile(all_loss, [25, 75])\n",
    "bin_width = 2 * (q75 - q25) * len(all_loss) ** (-1/3)\n",
    "bins = round((all_loss.max() - all_loss.min()) / bin_width)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(all_loss, density=False, bins=bins)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.ylabel('Ratio')\n",
    "plt.xlabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_loss_diff = []\n",
    "for inner_loss_token in inner_loss_token_dynamic[:1000]:\n",
    "    for token_loss in inner_loss_token:\n",
    "        losses = [loss[1] for loss in list(token_loss.values())[1:]]\n",
    "        for loss in losses:\n",
    "            all_loss_diff.append(loss)\n",
    "all_loss_diff = np.array(all_loss_diff)\n",
    "q25, q75 = np.percentile(all_loss_diff, [25, 75])\n",
    "bin_width = 2 * (q75 - q25) * len(all_loss_diff) ** (-1/3)\n",
    "bins = round((all_loss_diff.max() - all_loss_diff.min()) / bin_width)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(all_loss_diff, density=True, bins=bins)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Loss Difference')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hist, xedges, yedges = np.histogram2d(\n",
    "    all_loss, all_loss_diff, bins=10, range=[[0, 10], [-5, 5]])\n",
    "\n",
    "xedges = [round(x) for x in xedges]\n",
    "yedges = [round(y) for y in yedges]\n",
    "\n",
    "cmap = sns.cm.rocket_r\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = sns.heatmap(\n",
    "        hist, linewidth=0.8, cmap=cmap,\n",
    "        xticklabels=xedges[:-1], yticklabels=yedges[:-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meta_kg.utils.py_io import *\n",
    "\n",
    "clutrr_train = read_jsonl('./data/clutrr_simple/train.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clutrr_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "relation_inner = [fact[1] for data in clutrr_train for fact in data['facts']]\n",
    "Counter(relation_inner).most_common(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_outer = [q[2] for data in clutrr_train for q in data['questions']]\n",
    "Counter(relation_outer).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "checkpoint = \"./output/20221205-051520/epoch=0-step=7200.ckpt\"\n",
    "\n",
    "model = torch.load(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "gpt = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = [\"fact 1 123: \", \"fact 2 123: \", \"fact 3 123: \"]\n",
    "input_ids = tokenizer(\"fact 1 123: 1sddfgtg \", return_tensors='pt').input_ids\n",
    "\n",
    "outputs = gpt.generate(input_ids, max_length=20, num_beams=5, do_sample=False, top_k=5, top_p=None, num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_param = gpt.state_dict()\n",
    "for param in model['state_dict']:\n",
    "    if \"model.model\" in param:\n",
    "        new_param = param.replace(\"model.model\", \"\")\n",
    "        gpt2_param[new_param] = model['state_dict'][param]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[tokenizer.decode(out, skip_special_tokens=True) for out in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "max_length = 20\n",
    "generation_config = GenerationConfig.from_pretrained(\n",
    "    \"distilgpt2\",\n",
    "    num_beams=5,\n",
    "    early_stopping=True,\n",
    "    top_p=0.5,\n",
    "    top_k=5,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"distilgpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "inputs = tokenizer([\"Today is\"], return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generation_config = generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(input_ids=inputs.input_ids, max_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Today is a new feature for the Windows Phone 8.1 operating system.\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (514494627.py, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [1]\u001b[0;36m\u001b[0m\n\u001b[0;31m    for each node i:\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class Node:\n",
    "    def __init__(self, id):\n",
    "        self.id = id\n",
    "        self.neighbors = []\n",
    "        self.slice = None\n",
    "        self.random_number = None\n",
    "\n",
    "    def add_neighbor(self, node):\n",
    "        self.neighbors.append(node)\n",
    "\n",
    "    def set_slice(self, slice):\n",
    "        self.slice = slice\n",
    "\n",
    "    def set_random_number(self, random_number):\n",
    "        self.random_number = random_number\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Node {self.id}\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    \n",
    "nodes = [Node(i) for i in range(20)]\n",
    "\n",
    "for i in nodes:\n",
    "    i.neighbors = {}\n",
    "    i.slice = (i.random_number / (20/10))\n",
    "    j = random.choice(i.neighbors.keys())\n",
    "    send_gossip(i, j, randomly selected node from slice i.slice)\n",
    "\n",
    "// Gossip phase\n",
    "for round = 1 to num_rounds:\n",
    "    for each node i:\n",
    "        j = randomly selected neighbor of i\n",
    "        k = randomly selected node from slice i.slice\n",
    "        send_gossip(i, j, k)\n",
    "        \n",
    "        if j.slice == i.slice:\n",
    "            l = randomly selected neighbor of j\n",
    "            send_gossip(j, i, l)\n",
    "\n",
    "// Termination phase\n",
    "for each node i:\n",
    "    stop_gossiping(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.randint(0, 10) / (20 / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "470f44e489c3417f40e6fbafbb8f6893ee0c258fcccc4737e0ea9152abfd2d49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
